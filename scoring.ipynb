{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65f3a52-a587-4cf1-9e10-40afcd955e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gower\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba75f2fe-9371-4820-880e-7acdeeabfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_LinearSVC = pd.read_pickle('./data/y_pred_LinearSVC.pkl')\n",
    "y_LogReg = pd.read_pickle('./data/y_pred_LogReg.pkl')\n",
    "y_RidgeReg = pd.read_pickle('./data/y_pred_RidgeReg.pkl')\n",
    "X = pd.read_pickle('./data/unlabeled_behavior.pkl')\n",
    "embedding = pd.read_pickle('./data/embedding.pkl')\n",
    "\n",
    "#define parameter ranges\n",
    "#we originally wanted to search over the range commented below, but it took 15 hours of uninterrupted\n",
    "#compute time to generate all of the models at min_samples=95, so we'll just run 95 and 200\n",
    "min_samples_range = [95, 200] #np.arange(95, 201, 15)\n",
    "max_eps_range = np.arange(1.0, 2.1, 0.5)\n",
    "eps_range = np.arange(1.0, 2.1, 0.5)\n",
    "\n",
    "#create a data structure to store cluster assignments and scorings\n",
    "Key = namedtuple('Key', ['s', 'me', 'e'])\n",
    "'''\n",
    "#This is how Labels_Scores was initialized, we had to interrupt execution and save it after the s=95\n",
    "#runs completed.\n",
    "Labels_Scores = {Key(s, me, e):{'labels_g':None, 'labels_e':None, 'relabels_g':None, 'relabels_e':None,\n",
    "                                'score_e':{'lsvm':None, 'lr':None, 'rr':None},\n",
    "                                'score_g':{'lsvm':None, 'lr':None, 'rr':None}}\n",
    "                 for s, me, e in [[s, me, e] for s in min_samples_range\n",
    "                                             for me in max_eps_range\n",
    "                                             for e in eps_range]}\n",
    "'''\n",
    "#read in the partially filled Labels_Scores structure\n",
    "with open('./data/labels_scores.pkl', 'rb') as handle:\n",
    "    Labels_Scores = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c429e51-3463-4eaa-a092-41690aa743ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we've seen the initial plots, let's relabel the clusters, compute mutual information scores,\n",
    "#and generate plots with relabelings and scores\n",
    "for s, me, e in [[s, me, e] for s in min_samples_range\n",
    "                            for me in max_eps_range\n",
    "                            for e in eps_range]:\n",
    "    \n",
    "    key = Key(s, me, e)\n",
    "    \n",
    "    #create relabelings - from manual inspection, we can name everything outside cluster 0 as class 1\n",
    "    def relabel(arr):\n",
    "        ret = []\n",
    "        for i in arr:\n",
    "            if i == 0:\n",
    "                ret.append(0)\n",
    "            else:\n",
    "                ret.append(1)\n",
    "        return np.array(ret)\n",
    "    \n",
    "    Labels_Scores[key]['relabels_g'] = relabel(Labels_Scores[key]['labels_g'])\n",
    "    Labels_Scores[key]['relabels_e'] = relabel(Labels_Scores[key]['labels_e'])    \n",
    "\n",
    "    #compute mutual information scores\n",
    "    Labels_Scores[key]['score_g']['lsvm'] = nmi(Labels_Scores[key]['relabels_g'], y_LinearSVC)\n",
    "    Labels_Scores[key]['score_g']['lr'] = nmi(Labels_Scores[key]['relabels_g'], y_LogReg)\n",
    "    Labels_Scores[key]['score_g']['rr'] = nmi(Labels_Scores[key]['relabels_g'], y_RidgeReg)\n",
    "    Labels_Scores[key]['score_e']['lsvm'] = nmi(Labels_Scores[key]['relabels_e'], y_LinearSVC)\n",
    "    Labels_Scores[key]['score_e']['lr'] = nmi(Labels_Scores[key]['relabels_e'], y_LogReg)\n",
    "    Labels_Scores[key]['score_e']['rr'] = nmi(Labels_Scores[key]['relabels_e'], y_RidgeReg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5c4e78-584a-4b99-a2f1-9a1041897f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the best model and score\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for s, me, e in [[s, me, e] for s in [95]\n",
    "                            for me in max_eps_range\n",
    "                            for e in eps_range]:\n",
    "    key = Key(s, me, e)\n",
    "    \n",
    "    for k, v in Labels_Scores[key]['score_e'].items():\n",
    "        if v > best_score:\n",
    "            best_model = (s, me, e, k, 'euclidean')\n",
    "            best_score = v\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for k, v in Labels_Scores[key]['score_g'].items():\n",
    "        if v > best_score:\n",
    "            best_model = (s, me, e, k, 'gower')\n",
    "            best_score = v\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebe199f-319a-443b-8e52-a9dd51f7b612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 1.0, 1.0, 'rr', 'euclidean')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3d979a-85b7-4c8c-a840-18e2500aee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004819616139413582"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816bc495-8fc1-4c9d-a123-0a367331e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/labels_scores.pkl', 'wb') as handle:\n",
    "    pickle.dump(Labels_Scores, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
