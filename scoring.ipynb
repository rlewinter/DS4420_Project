{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c65f3a52-a587-4cf1-9e10-40afcd955e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gower\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba75f2fe-9371-4820-880e-7acdeeabfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_LinearSVC = pd.read_pickle('./data/y_pred_LinearSVC.pkl')\n",
    "y_LogReg = pd.read_pickle('./data/y_pred_LogReg.pkl')\n",
    "y_RidgeReg = pd.read_pickle('./data/y_pred_RidgeReg.pkl')\n",
    "X = pd.read_pickle('./data/unlabeled_behavior.pkl')\n",
    "embedding = pd.read_pickle('./data/embedding.pkl')\n",
    "\n",
    "#define parameter ranges\n",
    "#we originally wanted to search over the range commented below, but it took 15 hours of uninterrupted\n",
    "#compute time to generate all of the models at min_samples=95, so we'll just run 95 and 200\n",
    "min_samples_range = [200] #np.arange(95, 201, 15)\n",
    "max_eps_range = np.arange(1.0, 2.1, 0.5)\n",
    "eps_range = np.arange(1.0, 2.1, 0.5)\n",
    "\n",
    "#create a data structure to store cluster assignments and scorings\n",
    "Key = namedtuple('Key', ['s', 'me', 'e'])\n",
    "'''\n",
    "#This is how Labels_Scores was initialized, we had to interrupt execution and save it after the s=95\n",
    "#runs completed.\n",
    "Labels_Scores = {Key(s, me, e):{'labels_g':None, 'labels_e':None, 'relabels_g':None, 'relabels_e':None,\n",
    "                                'score_e':{'lsvm':None, 'lr':None, 'rr':None},\n",
    "                                'score_g':{'lsvm':None, 'lr':None, 'rr':None}}\n",
    "                 for s, me, e in [[s, me, e] for s in min_samples_range\n",
    "                                             for me in max_eps_range\n",
    "                                             for e in eps_range]}\n",
    "'''\n",
    "#read in the partially filled Labels_Scores structure\n",
    "with open('./data/labels_scores.pkl', 'rb') as handle:\n",
    "    Labels_Scores = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bddd0546-96ea-4d61-906d-e00fd0bcb653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_with_ys(x1, x2, names, y_class, y_cluster, ext_names=False, relabeled=False, score=None)\n",
    "# Generates a 2d plot of the given data. If only y_class is given, data points will be colored by\n",
    "# classification. If y_cluster is also given, data points will be colored by cluster label with shapes\n",
    "# corresponding to classification. Intended for use with embeddings generated by TSNE. Plots with\n",
    "# extended names will go to a scratch folder so we can compare selections of parameters for OPTICS.\n",
    "# Once we've chosen parameters these will be used through all future plots so the plots that go\n",
    "# into our report can go without extended names.\n",
    "# Variables:\n",
    "# x1        -  array representing the position on the x-axis of each point in a 2d embedding from TSNE\n",
    "# x2        -  array representing the position on the y-axis of each point in a 2d embedding from TSNE\n",
    "# names     -  an array of string names for the classification algorithm used (index 0) and\n",
    "#              the clustering algorithm used (index 1). If ext_names=True, also includes the \n",
    "#              min_samples (index 2), max_eps (index 3), eps (index 4), and the distance \n",
    "#              metric (index 5). For use in plotting.\n",
    "# y_class   -  an array of classifications from a supervised model\n",
    "# y_cluster -  an array of cluster labelings\n",
    "# ext_names -  whether to look for extended names for the plot (default: False)\n",
    "# relabeled -  whether clusters have been relabeled to enable computation of mutual information scores\n",
    "#              (default: False)\n",
    "# score     -  if relabeled=True, mutual information score of the clustering against the classification\n",
    "#              (default: None)\n",
    "@mpl.rc_context({'figure.figsize': [12.0, 8.0]})\n",
    "def plot_with_ys(x1, x2, names, y_class, y_cluster, ext_names=False, relabeled=False, score=None):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "        \n",
    "    #create a colormap of the correct size, doing this bc just giving 'tab10' to the cmap\n",
    "    #parameter gives colors from each end of the palette instead of sequentially\n",
    "    colors = mpl.colors.ListedColormap(plt.get_cmap('tab10')(np.arange(len(np.unique(y_cluster)))))\n",
    "\n",
    "    #plot the two predicted classes with different markers, coloring by cluster assignment\n",
    "    x1_normal = [a for a,b in zip(x1, y_class) if b == 0]\n",
    "    x2_normal = [a for a,b in zip(x2, y_class) if b == 0]\n",
    "    scatter1 = ax.scatter(x1_normal, x2_normal, marker='|', cmap=colors,\n",
    "                          c=y_cluster[np.argwhere(y_class == 0)])\n",
    "    \n",
    "    x1_outlier = [a for a,b in zip(x1, y_class) if b == 1]\n",
    "    x2_outlier = [a for a,b in zip(x2, y_class) if b == 1]\n",
    "    scatter2 = ax.scatter(x1_outlier, x2_outlier, marker='_', cmap=colors,\n",
    "                          c=y_cluster[np.argwhere(y_class == 1)])\n",
    "\n",
    "    #create a legend for differentiating between colors\n",
    "    #handles1, labels1 = scatter1.legend_elements()\n",
    "    #handles2, labels2 = scatter2.legend_elements()\n",
    "    #handles = handles1 + handles2\n",
    "    #labels = labels1 + labels2\n",
    "    legend1 = ax.legend(*scatter1.legend_elements(), loc=\"lower left\", title=\"Clusters\")\n",
    "    ax.add_artist(legend1)\n",
    "\n",
    "    #create a legend from scratch for differentiating between markers\n",
    "    vline = mlines.Line2D([], [], color='black', marker='|', linestyle='None',\n",
    "                          markersize=10, label='0 (normal)')\n",
    "    hline = mlines.Line2D([], [], color='black', marker='_', linestyle='None',\n",
    "                          markersize=10, label='1 (outlier)')\n",
    "    legend2 = ax.legend(handles=[vline, hline], loc=\"lower right\", title=\"Classes\")\n",
    "\n",
    "    if relabeled: #add text reporting the mutual information score\n",
    "        plt.text()\n",
    "\n",
    "    #insert given names to title and filename\n",
    "    if ext_names: #with names for min_samples, max_eps, eps, and distance metric\n",
    "        if relabeled: #plot has relabeled clusterings\n",
    "            plt.title('TSNE Relabeled '+names[1]+' Clusterings & ' +names[0]+' Classifications s'\n",
    "                      +names[2]+' me'+names[3]+' e'+names[4]+' '+names[5])\n",
    "            filename = str('./figures/scratch/TSNE_relabeled_'+names[1]+'_'+names[0]+'_s'\n",
    "                           +names[2]+'_me'+names[3]+'_e'+names[4]+'_'+names[5]+'.png')\n",
    "        else: #plot has original clusterings\n",
    "            plt.title('TSNE '+names[1]+' Clusterings & ' +names[0]+' Classifications s'\n",
    "                      +names[2]+' me'+names[3]+' e'+names[4]+' '+names[5])\n",
    "            filename = str('./figures/scratch/TSNE_'+names[1]+'_'+names[0]+'_s'+names[2]+'_me'\n",
    "                           +names[3]+'_e'+names[4]+'_'+names[5]+'.png')\n",
    "\n",
    "    else: #without names for min_samples, max_eps, eps, and distance metric\n",
    "        if relabeled: #plot has relabeled clusterings\n",
    "            plt.title('TSNE Relabeled '+names[1]+' Clusterings & ' +names[0]+' Classifications')\n",
    "            filename = './figures/TSNE_relabeled_'+names[1]+'_'+names[0]+'.png'\n",
    "        else:\n",
    "            plt.title('TSNE '+names[1]+' Clusterings & ' +names[0]+' Classifications')\n",
    "            filename = './figures/TSNE_'+names[1]+'_'+names[0]+'.png'\n",
    "\n",
    "    #plt.savefig(filename, format='png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e74f174-2c36-4878-a758-9659b2b20f5d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "#visually verifying that relabeling works as expected\n",
    "def relabel(arr):\n",
    "    ret = []\n",
    "    for i in arr:\n",
    "        if i == 0:\n",
    "            ret.append(0)\n",
    "        else:\n",
    "            ret.append(1)\n",
    "    return np.array(ret)\n",
    "\n",
    "foo = zip(Labels_Scores[Key(95, 1.0, 1.0)]['labels_e'],\n",
    "          relabel(Labels_Scores[Key(95, 1.0, 1.0)]['labels_e']))\n",
    "for a, b in foo:\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4b424ee-2d2f-410f-afe5-441d79661f6b",
   "metadata": {},
   "source": [
    "#try some plots\n",
    "plot_with_ys(embedding[0], embedding[1],\n",
    "             ['RidgeReg', 'OPTICS', '95', '1.0', '1.0', 'euclidean'],\n",
    "             y_RidgeReg, Labels_Scores[Key(95, 1.0, 1.0)]['labels_e'],\n",
    "             True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d3bf943-ba35-49d7-989a-8469fd86e4a9",
   "metadata": {},
   "source": [
    "#check a score\n",
    "nmi(relabel(Labels_Scores[Key(95, 1.0, 1.0)]['labels_e']),\n",
    "                             y_RidgeReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c429e51-3463-4eaa-a092-41690aa743ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we've seen the initial plots, let's relabel the clusters, compute mutual information scores,\n",
    "#and generate plots with relabelings and scores\n",
    "for s, me, e in [[s, me, e] for s in [95]\n",
    "                            for me in max_eps_range\n",
    "                            for e in eps_range]:\n",
    "    \n",
    "    key = Key(s, me, e)\n",
    "    \n",
    "    #create relabelings - from manual inspection, we can name everything outside cluster 0 as class 1\n",
    "    def relabel(arr):\n",
    "        ret = []\n",
    "        for i in arr:\n",
    "            if i == 0:\n",
    "                ret.append(0)\n",
    "            else:\n",
    "                ret.append(1)\n",
    "        return np.array(ret)\n",
    "    \n",
    "    Labels_Scores[key]['relabels_g'] = relabel(Labels_Scores[key]['labels_g'])\n",
    "    Labels_Scores[key]['relabels_e'] = relabel(Labels_Scores[key]['labels_e'])    \n",
    "\n",
    "    #compute mutual information scores\n",
    "    Labels_Scores[key]['score_g']['lsvm'] = nmi(Labels_Scores[key]['relabels_g'], y_LinearSVC)\n",
    "    Labels_Scores[key]['score_g']['lr'] = nmi(Labels_Scores[key]['relabels_g'], y_LogReg)\n",
    "    Labels_Scores[key]['score_g']['rr'] = nmi(Labels_Scores[key]['relabels_g'], y_RidgeReg)\n",
    "    Labels_Scores[key]['score_e']['lsvm'] = nmi(Labels_Scores[key]['relabels_e'], y_LinearSVC)\n",
    "    Labels_Scores[key]['score_e']['lr'] = nmi(Labels_Scores[key]['relabels_e'], y_LogReg)\n",
    "    Labels_Scores[key]['score_e']['rr'] = nmi(Labels_Scores[key]['relabels_e'], y_RidgeReg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d5c4e78-584a-4b99-a2f1-9a1041897f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the best model and score\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for s, me, e in [[s, me, e] for s in [95]\n",
    "                            for me in max_eps_range\n",
    "                            for e in eps_range]:\n",
    "    key = Key(s, me, e)\n",
    "    \n",
    "    for k, v in Labels_Scores[key]['score_e'].items():\n",
    "        if v > best_score:\n",
    "            best_model = (s, me, e, k, 'euclidean')\n",
    "            best_score = v\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for k, v in Labels_Scores[key]['score_g'].items():\n",
    "        if v > best_score:\n",
    "            best_model = (s, me, e, k, 'gower')\n",
    "            best_score = v\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ebe199f-319a-443b-8e52-a9dd51f7b612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 1.0, 1.0, 'rr', 'euclidean')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf3d979a-85b7-4c8c-a840-18e2500aee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004819616139413582"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac2493ee-3e73-4c8a-a0d4-a1d31c074529",
   "metadata": {},
   "source": [
    "#dont run this until everything is done\n",
    "\n",
    "with open('./data/labels_scores.pkl', 'wb') as handle:\n",
    "    pickle.dump(Labels_Scores, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
