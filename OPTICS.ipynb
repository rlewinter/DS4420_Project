{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acae2e7c-6bdb-467a-afe3-077ccbb04116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gower in /home/lewinter.r/.conda/envs/DS4420/lib/python3.8/site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in /home/lewinter.r/.conda/envs/DS4420/lib/python3.8/site-packages (from gower) (1.21.5)\n",
      "Requirement already satisfied: scipy in /home/lewinter.r/.conda/envs/DS4420/lib/python3.8/site-packages (from gower) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gower\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gower\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0688a1-eacd-4b7e-968d-9559fbfa62de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OPTICS\n",
    "\n",
    "We will run OPTICS with various values of min_samples, max_eps, and eps. Who only these three? After running models with various parameters, we found that configuring these three parameters has the most effect on model behaviors. Additionally, OPTICS takes time to run, so we want to cut down the number of parameter combinations to try. What about the other parameters?\n",
    "\n",
    "- metric: this is the metric used for distance computation. Initially, we tested out various distance metrics that work both for OPTICS and ‘kd_tree’ (the algo we used to compute the nearest neighbors, explained later), and there was no significant impact on the clustering results. Therefore, it’s reasonable to use the default option, ‘minkowski.’ In a combination with the next parameter p=2, the ‘minkowski’ here is really the euclidean distance. However, since we want to make sure that euclidean distance is used, we explicitly specify the metric = ‘euclidean.’ For the model that uses the Gower distance, we specify the metric as 'precomputed.'\n",
    "- p: this is the parameter for the Minkowski metric. The default =2 which sets the distance metric to euclidean_distance, which is what we used.\n",
    "- metric_params: this is to add any additional keyword arguments for the metric function; since we used the default metric, we don’t have to add any more.\n",
    "- cluster_method: this specifies the extraction method used to extract clusters using the calculated reachability and ordering. There are two options ‘xi’ and ‘dbscan.’ We tested out both options and found that ‘dbscan’ results in significantly better clusterings.\n",
    "- xi: this determines the minimum steepness on the reachability plot that constitutes a cluster boundary. It is only used when the cluster method is ‘xi.’ Since we used dbscan, we don’t need to configure this param.\n",
    "- predecessor_correction: This parameter has minimal effect on most datasets, and it is used only when cluster_method='xi,' therefore we did not use it.\n",
    "- min_cluster_size: this param specifies the minimum number in an OPTICS cluster and it is only used when the cluster extraction method is ‘xi.’ Since we mainly used the ‘dbscan’ cluster extraction method, we did not use this param. It will be set as the same as the min_samples if it’s not specified.\n",
    "- algorithm: This algorithm is used to compute the nearest neighbors. We choose ‘kd_tree’ as it works well for low-dimensional data.\n",
    "- leaf_size: this param can affect the speed of the construction and query, as well as the memory required to store the tree. The default value is 30. Speed and memory were not our top priorities, therefore, we left it as default.\n",
    "- memory: used to cache the output of the computation of the tree. By default, no caching is done. Similar to the previous param, not our top priority.\n",
    "\n",
    "How did we choose the range of min_samples to try?\n",
    "We ran models with min_samples from 5 to 220 with an increment of 5, then ran a final model with a min_samples of 250. We plotted the clustering with the tsne embeddings of the classifications from the previous project. We inspected these plots as the min_sample changed. We found that min_sample of 95 to 200 will result in more separated/clear clusters, with the ‘dbscan’ cluster extraction method. With the ‘xi’ extraction method, although as min_samples increased, the number of clusters decreased, when plotted against the classifications, the clusters were not clearly separated. We will run OPTICS with the Gower distance with min_samples in range (95, 201) with an increment of 15. We expect the clustering to be better than the OPTICS model fitted on the original unlabeled data.\n",
    "\n",
    "How did we choose the range of max_eps to try?\n",
    "Similar to the above, we ran models with max_eps from 0.2 to 1.5 with an increment of 0.2 and inspected the clustering plot. Max_eps is the maximum distance between two samples for one to be considered as in the neighborhood of the other. Initially, we did not specify this value. Without doing so, it will be set as np.inf (infinity), which will identify clusters across all scales. We found that with a max_eps of 1 or above, with the combination of other params, our models produce great results. We will run OPTICS with the Gower distance with max_eps in range (1, 2.1) with an increment of 0.5.\n",
    "\n",
    "How did we choose the range of eps to try?\n",
    "Eps indicates the maximum distance between two samples for one to be considered as in the neighborhood of the other. If non-specified, the default is set to be the same as the max_eps. This param is only used when the cluster extraction method is ‘dbscan,’ which is what we used. We run models with eps in a range of 0.2 to 1.5 with an increment of 0.2 and found that with eps greater than 1, the clusters produced were better. Therefore, we will use an eps in range (1, 2.1) with an increment of 0.5 to run OPTICS models with the Gower distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5b1ab",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a02a1f-83c2-4c39-a3d6-ac4c88997a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_LinearSVC = pd.read_pickle('./data/y_pred_LinearSVC.pkl')\n",
    "y_LogReg = pd.read_pickle('./data/y_pred_LogReg.pkl')\n",
    "y_RidgeReg = pd.read_pickle('./data/y_pred_RidgeReg.pkl')\n",
    "X = pd.read_pickle('./data/unlabeled_behavior.pkl')\n",
    "embedding = pd.read_pickle('./data/embedding.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039d486-5055-42c4-be35-0a34b161a57c",
   "metadata": {},
   "source": [
    "Generate Gower matrix and data structure to store cluster assignments and scorings from parameter search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d5bf42-e050-478c-a16e-3e5b8a3b0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gower = pd.DataFrame(gower.gower_matrix(X, cat_features=[False, False, False, False, True,\n",
    "                                                           False, False, False, True]))\n",
    "\n",
    "#define parameter ranges\n",
    "#we originally wanted to search over the range commented below, but it took 15 hours of uninterrupted\n",
    "#compute time to generate all of the models at min_samples=95, so we'll just run 95 and 200\n",
    "min_samples_range = [200] #np.arange(95, 201, 15)\n",
    "max_eps_range = np.arange(1.0, 2.1, 0.5)\n",
    "eps_range = np.arange(1.0, 2.1, 0.5)\n",
    "\n",
    "#create a data structure to store cluster assignments and scorings\n",
    "Key = namedtuple('Key', ['s', 'me', 'e'])\n",
    "'''\n",
    "#This is how Labels_Scores was initialized, we had to interrupt execution and save it after the s=95\n",
    "#runs completed.\n",
    "Labels_Scores = {Key(s, me, e):{'labels_g':None, 'labels_e':None, 'relabels_g':None, 'relabels_e':None,\n",
    "                                'score_e':{'lsvm':None, 'lr':None, 'rr':None},\n",
    "                                'score_g':{'lsvm':None, 'lr':None, 'rr':None}}\n",
    "                 for s, me, e in [[s, me, e] for s in min_samples_range\n",
    "                                             for me in max_eps_range\n",
    "                                             for e in eps_range]}\n",
    "'''\n",
    "#read in the partially filled Labels_Scores structure\n",
    "with open('./data/labels_scores.pkl', 'rb') as handle:\n",
    "    Labels_Scores = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08d066d",
   "metadata": {},
   "source": [
    "Define plotting function (this is modified from the version for TSNE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa2d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_with_ys(x1, x2, names, y_class, y_cluster, ext_names=False, relabeled=False, score=None)\n",
    "# Generates a 2d plot of the given data. If only y_class is given, data points will be colored by\n",
    "# classification. If y_cluster is also given, data points will be colored by cluster label with shapes\n",
    "# corresponding to classification. Intended for use with embeddings generated by TSNE. Plots with\n",
    "# extended names will go to a scratch folder so we can compare selections of parameters for OPTICS.\n",
    "# Once we've chosen parameters these will be used through all future plots so the plots that go\n",
    "# into our report can go without extended names.\n",
    "# Variables:\n",
    "# x1        -  array representing the position on the x-axis of each point in a 2d embedding from TSNE\n",
    "# x2        -  array representing the position on the y-axis of each point in a 2d embedding from TSNE\n",
    "# names     -  an array of string names for the classification algorithm used (index 0) and\n",
    "#              the clustering algorithm used (index 1). If ext_names=True, also includes the \n",
    "#              min_samples (index 2), max_eps (index 3), eps (index 4), and the distance \n",
    "#              metric (index 5). For use in plotting.\n",
    "# y_class   -  an array of classifications from a supervised model\n",
    "# y_cluster -  an array of cluster labelings\n",
    "# ext_names -  whether to look for extended names for the plot (default: False)\n",
    "# relabeled -  whether clusters have been relabeled to enable computation of mutual information scores\n",
    "#              (default: False)\n",
    "# score     -  if relabeled=True, mutual information score of the clustering against the classification\n",
    "#              (default: None)\n",
    "@mpl.rc_context({'image.cmap': 'tab10', 'figure.figsize': [12.0, 8.0]})\n",
    "def plot_with_ys(x1, x2, names, y_class, y_cluster, ext_names=False, relabeled=False, score=None):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "        \n",
    "    #create a colormap of the correct size, doing this bc just giving 'tab10' to the cmap\n",
    "    #parameter gives colors from each end of the palette instead of sequentially\n",
    "    colors = mpl.colors.ListedColormap(plt.get_cmap('tab10')(np.arange(len(np.unique(y_cluster)))))\n",
    "\n",
    "    #plot the two predicted classes with different markers, coloring by cluster assignment\n",
    "    x1_normal = [a for a,b in zip(x1, y_class) if b == 0]\n",
    "    x2_normal = [a for a,b in zip(x2, y_class) if b == 0]\n",
    "    scatter1 = ax.scatter(x1_normal, x2_normal, marker='|', cmap=colors,\n",
    "                          c=y_cluster[np.argwhere(y_class == 0)])\n",
    "\n",
    "    x1_outlier = [a for a,b in zip(x1, y_class) if b == 1]\n",
    "    x2_outlier = [a for a,b in zip(x2, y_class) if b == 1]\n",
    "    scatter2 = ax.scatter(x1_outlier, x2_outlier, marker='_', cmap=colors,\n",
    "                          c=y_cluster[np.argwhere(y_class == 1)])\n",
    "\n",
    "    #create a legend for differentiating between colors\n",
    "    legend1 = ax.legend(*scatter1.legend_elements(), loc=\"lower left\", title=\"Clusters\")\n",
    "    ax.add_artist(legend1)\n",
    "\n",
    "    #create a legend from scratch for differentiating between markers\n",
    "    vline = mlines.Line2D([], [], color='black', marker='|', linestyle='None',\n",
    "                          markersize=10, label='0 (normal)')\n",
    "    hline = mlines.Line2D([], [], color='black', marker='_', linestyle='None',\n",
    "                          markersize=10, label='1 (outlier)')\n",
    "    legend2 = ax.legend(handles=[vline, hline], loc=\"lower right\", title=\"Classes\")\n",
    "\n",
    "    #if relabeled: #add text reporting the mutual information score\n",
    "        #TODO\n",
    "\n",
    "    #insert given names to title and filename\n",
    "    if ext_names: #with names for min_samples, max_eps, eps, and distance metric\n",
    "        if relabeled: #plot has relabeled clusterings\n",
    "            plt.title('TSNE Relabeled '+names[1]+' Clusterings & ' +names[0]+' Classifications s'\n",
    "                      +names[2]+' me'+names[3]+' e'+names[4]+' '+names[5])\n",
    "            filename = str('./figures/scratch/TSNE_relabeled_'+names[1]+'_'+names[0]+'_s'\n",
    "                           +names[2]+'_me'+names[3]+'_e'+names[4]+'_'+names[5]+'.png')\n",
    "        else: #plot has original clusterings\n",
    "            plt.title('TSNE '+names[1]+' Clusterings & ' +names[0]+' Classifications s'\n",
    "                      +names[2]+' me'+names[3]+' e'+names[4]+' '+names[5])\n",
    "            filename = str('./figures/scratch/TSNE_'+names[1]+'_'+names[0]+'_s'+names[2]+'_me'\n",
    "                           +names[3]+'_e'+names[4]+'_'+names[5]+'.png')\n",
    "\n",
    "    else: #without names for min_samples, max_eps, eps, and distance metric\n",
    "        if relabeled: #plot has relabeled clusterings\n",
    "            plt.title('TSNE Relabeled '+names[1]+' Clusterings & ' +names[0]+' Classifications')\n",
    "            filename = './figures/TSNE_relabeled_'+names[1]+'_'+names[0]+'.png'\n",
    "        else:\n",
    "            plt.title('TSNE '+names[1]+' Clusterings & ' +names[0]+' Classifications')\n",
    "            filename = './figures/TSNE_'+names[1]+'_'+names[0]+'.png'\n",
    "\n",
    "    plt.savefig(filename, format='png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d1ec0-0a20-4438-94b4-8db8bf1cc005",
   "metadata": {},
   "source": [
    "\n",
    "Labels_Scores = \n",
    "Labels_Scores = Let's search over the range of parameters identified by our initial runs. We will generate and plot clusterings for each parameter combination, relabel clusterings so that the largest component is 0 (normal) and all others are 1 (outlier), compute mutual information scores against classifications, and replot with relabeled clusters and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb293b-b24a-46aa-a09d-d00f27b98128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#first let's just compute the cluster assignments and plot them\n",
    "for s in min_samples_range:\n",
    "    \n",
    "    for me in max_eps_range:\n",
    "        \n",
    "        #fit model with gower distance\n",
    "        model_g = OPTICS(min_samples=s, max_eps=me, metric='precomputed',\n",
    "                         algorithm='brute', n_jobs=-1)\n",
    "        model_g.fit(X_gower)\n",
    "        \n",
    "        #fit model with euclidean distance\n",
    "        model_e = OPTICS(min_samples=s, max_eps=me, metric='euclidean',\n",
    "                         algorithm='kd_tree', n_jobs=-1)\n",
    "        model_e.fit(X)\n",
    "        \n",
    "        for e in eps_range:\n",
    "            \n",
    "            #extract clusters \n",
    "            labels_g = cluster_optics_dbscan(reachability=model_g.reachability_,\n",
    "                                             core_distances=model_g.core_distances_,\n",
    "                                             ordering=model_g.ordering_, eps=e)\n",
    "            labels_e = cluster_optics_dbscan(reachability=model_e.reachability_,\n",
    "                                             core_distances=model_e.core_distances_,\n",
    "                                             ordering=model_e.ordering_, eps=e)\n",
    "            \n",
    "            #add clusters to Labels_Scores dictionary\n",
    "            Labels_Scores[Key(s, me, e)]['labels_g'] = labels_g\n",
    "            Labels_Scores[Key(s, me, e)]['labels_e'] = labels_e\n",
    "            \n",
    "            #plot original clusterings for gower\n",
    "            plot_with_ys(embedding[0], embedding[1], \n",
    "                         ['LinearSVC', 'OPTICS', str(s), str(me), str(e), 'gower'],\n",
    "                         y_LinearSVC, labels_g, ext_names=True)\n",
    "            plot_with_ys(embedding[0], embedding[1], \n",
    "                         ['LogReg', 'OPTICS', str(s), str(me), str(e), 'gower'],\n",
    "                         y_LogReg, labels_g, ext_names=True)\n",
    "            plot_with_ys(embedding[0], embedding[1], \n",
    "                         ['RidgeReg', 'OPTICS', str(s), str(me), str(e), 'gower'],\n",
    "                         y_RidgeReg, labels_g, ext_names=True)\n",
    "            \n",
    "            #plot original clusterings for euclidean\n",
    "            plot_with_ys(embedding[0], embedding[1], \n",
    "                         ['LinearSVC', 'OPTICS', str(s), str(me), str(e), 'euclidean'],\n",
    "                         y_LinearSVC, labels_e, ext_names=True)\n",
    "            plot_with_ys(embedding[0], embedding[1], \n",
    "                         ['LogReg', 'OPTICS', str(s), str(me), str(e), 'euclidean'],\n",
    "                         y_LogReg, labels_e, ext_names=True)\n",
    "            plot_with_ys(embedding[0], embedding[1], \n",
    "                         ['RidgeReg', 'OPTICS', str(s), str(me), str(e), 'euclidean'],\n",
    "                         y_RidgeReg, labels_e, ext_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49fc40e-dedf-4538-a844-b2d2a1400ddb",
   "metadata": {},
   "source": [
    "Pickle data structure of labels and scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be0a74-8bfc-44b9-94f3-57e2ce4c9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/labels_scores.pkl', 'wb') as handle:\n",
    "    pickle.dump(Labels_Scores, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
